## 🚀 프로젝트 소개  
- 2022년 진행한 단국대 오픈소스AI응용 텀프로젝트.
- 사람은 다른 사람의 감정을 판단할 때 말투, 행동 등을 보고 파악하기도 하지만 제일 먼저 보는 것은 '표정'이다.
- 그러나 정확히 얼굴의 어느 부분을 보고 판단하는지에 대해 설명하는 건 쉽지 않다.
- 하지만 학습된 컴퓨터(모델)은 사람은 명확히 설명할 수 없는 어떠한 특징을 기반으로 감정을 판단할 것이다.
- 본 프로젝트는 이에 기반해 표정이미지들을 감정별로 분류하고, `CAM(Class Activation Map)`으로 분류과정을 시각화해본다.  
<br />

## 🔍 프로젝트 목적  
- CNN모델을 구축해 표정이미지들을 감정별로 분류한다
- CAM을 통해 분류과정에서의 중요 요소들을 시각적으로 파악해본다
<br />

## 📅 프로젝트 수행 일정
![a](https://user-images.githubusercontent.com/65762283/207514002-f1bd55a9-6ac9-4db7-be37-a4a04e2a11a6.png)  
<br />

## 🏃 프로젝트 수행 과정
### 데이터 수집
- 처음엔 구글링을 통해 표정이미지들을 모으고자 하였다.
- 그러나 수집된 이미지들은 사람의 표정 뿐만 아니라 표정에 관한 캐릭터나 그림 등이 더 많았다.
- 이들을 하나하나 걸러내는 건 어렵다고 판단, 이미 잘 구축된 데이터셋을 구하기로 하였다.
- 여러 데이터셋을 수집했으며, 데이터셋의 이미지들이 클래스별로 고르게 분포가 됐는지, 그리고 이미지에 붙여진 라벨링이 타당한지를 판단하여 최종적으로 데이터셋을 선정했다.  

### 모델 구성 (Transfer Learning & Fine Tuning)
- 최종적으로 선정한 데이터셋의 이미지가 총 1,000개 정도로 적은 편이었기 때문에 `전이학습`과 `데이터 어그멘테이션`을 통해 학습효과를 극대화하기로 했다.
